// Code generated by wit-bindgen-go. DO NOT EDIT.

// Package inference represents the imported interface "wasi:nn/inference@0.2.0-rc-2024-08-19".
//
// An inference "session" is encapsulated by a `graph-execution-context`. This structure
// binds a
// `graph` to input tensors before `compute`-ing an inference:
package inference

import (
	"github.com/bytecodealliance/wasm-tools-go/cm"
	"github.com/hayride-dev/bindgen/gen/go/wasi/nn/errors"
	"github.com/hayride-dev/bindgen/gen/go/wasi/nn/tensor"
)

// GraphExecutionContext represents the imported resource "wasi:nn/inference@0.2.0-rc-2024-08-19#graph-execution-context".
//
// Bind a `graph` to the input and output tensors for an inference.
//
// TODO: this may no longer be necessary in WIT
// (https://github.com/WebAssembly/wasi-nn/issues/43)
//
//	resource graph-execution-context
type GraphExecutionContext cm.Resource

// ResourceDrop represents the imported resource-drop for resource "graph-execution-context".
//
// Drops a resource handle.
//
//go:nosplit
func (self GraphExecutionContext) ResourceDrop() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_GraphExecutionContextResourceDrop((uint32)(self0))
	return
}

//go:wasmimport wasi:nn/inference@0.2.0-rc-2024-08-19 [resource-drop]graph-execution-context
//go:noescape
func wasmimport_GraphExecutionContextResourceDrop(self0 uint32)

// Compute represents the imported method "compute".
//
// Compute the inference on the given inputs.
//
// Note the expected sequence of calls: `set-input`, `compute`, `get-output`. TODO:
// this
// expectation could be removed as a part of
// https://github.com/WebAssembly/wasi-nn/issues/43.
//
//	compute: func() -> result<_, error>
//
//go:nosplit
func (self GraphExecutionContext) Compute() (result cm.Result[errors.Error, struct{}, errors.Error]) {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_GraphExecutionContextCompute((uint32)(self0), &result)
	return
}

//go:wasmimport wasi:nn/inference@0.2.0-rc-2024-08-19 [method]graph-execution-context.compute
//go:noescape
func wasmimport_GraphExecutionContextCompute(self0 uint32, result *cm.Result[errors.Error, struct{}, errors.Error])

// GetOutput represents the imported method "get-output".
//
// Extract the outputs after inference.
//
//	get-output: func(name: string) -> result<tensor, error>
//
//go:nosplit
func (self GraphExecutionContext) GetOutput(name string) (result cm.Result[tensor.Tensor, tensor.Tensor, errors.Error]) {
	self0 := cm.Reinterpret[uint32](self)
	name0, name1 := cm.LowerString(name)
	wasmimport_GraphExecutionContextGetOutput((uint32)(self0), (*uint8)(name0), (uint32)(name1), &result)
	return
}

//go:wasmimport wasi:nn/inference@0.2.0-rc-2024-08-19 [method]graph-execution-context.get-output
//go:noescape
func wasmimport_GraphExecutionContextGetOutput(self0 uint32, name0 *uint8, name1 uint32, result *cm.Result[tensor.Tensor, tensor.Tensor, errors.Error])

// SetInput represents the imported method "set-input".
//
// Define the inputs to use for inference.
//
//	set-input: func(name: string, tensor: tensor) -> result<_, error>
//
//go:nosplit
func (self GraphExecutionContext) SetInput(name string, tensor_ tensor.Tensor) (result cm.Result[errors.Error, struct{}, errors.Error]) {
	self0 := cm.Reinterpret[uint32](self)
	name0, name1 := cm.LowerString(name)
	tensor0 := cm.Reinterpret[uint32](tensor_)
	wasmimport_GraphExecutionContextSetInput((uint32)(self0), (*uint8)(name0), (uint32)(name1), (uint32)(tensor0), &result)
	return
}

//go:wasmimport wasi:nn/inference@0.2.0-rc-2024-08-19 [method]graph-execution-context.set-input
//go:noescape
func wasmimport_GraphExecutionContextSetInput(self0 uint32, name0 *uint8, name1 uint32, tensor0 uint32, result *cm.Result[errors.Error, struct{}, errors.Error])
